{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Movie Data (Inspecting and Visualizing)\n",
    "\n",
    "Three movie data files are stored in an s3 bucket(mlmovieinfofiles). These three data files will be loaded into dataframes, inspected and transformed for the machine learning training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading title.akas.tsv file into a DataFrame for inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#reading title.Akas.tsv file from s3 bucket and loading data into DataFrame\n",
    "titleAkas_df = pd.read_csv(\"s3://mlmovieinfofiles/title.akas.tsv\", sep='\\t', dtype={'region':'category','language':'category','types':'category','attributes':'category','ordering':'uint8','isOriginalTitle' : 'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data types\n",
    "titleAkas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate rows in titleAkas_df \n",
    "duplicate_Akasrows_df = titleAkas_df[titleAkas_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_Akasrows_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dimensionality of the DataFrame\n",
    "titleAkas_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing data in some of the columns in titleAkas_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart for data in column types\n",
    "sns.countplot(x='types', data=titleAkas_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart for data in column attributes\n",
    "sns.countplot(x='attributes', data=titleAkas_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed some of the cells in the DataFrame contain \"\\N\". Checking to see how many cells containing this data are in each column. Will need to get rid of them since they do not mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.title.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.region.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.language.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.types.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.attributes.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleAkas_df.isOriginalTitle.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking how many cells contain \"\\N\", decided to drop columns which have too many cells containing \"\\N\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping irrelevant columns \n",
    "titleAkas_df = titleAkas_df.drop(['types','attributes','language'],axis=1)\n",
    "titleAkas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading title.basics.tsv file into a DataFrame for inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading title.basics.tsv file from s3 bucket and loading data into DataFrame\n",
    "titleBasics_df = pd.read_csv(\"s3://mlmovieinfofiles/title.basics.tsv\", sep='\\t', dtype={'isAdult':'uint8', 'startYear':'category', 'endYear':'category','genres':'object'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleBasics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data types\n",
    "titleBasics_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming confusing column names\n",
    "titleBasics_df = titleBasics_df.rename(columns={'tconst': 'titleId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate rows in titleBasics_df\n",
    "duplicate_Basicsrows_df = titleBasics_df[titleBasics_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_Basicsrows_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dimensionality of the DataFrame\n",
    "titleBasics_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualizing data in some of the columns in titleBasics_df DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart for data in column titleType\n",
    "sns.countplot(x='titleType', data=titleBasics_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart for data in column endYear\n",
    "sns.countplot(x='endYear', data=titleBasics_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart for data in column endYear\n",
    "sns.countplot(x='runtimeMinutes', data=titleBasics_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, noticed some of the cells in the DataFrame contain \"\\N\". Checking to see how many cells containing this data are in each column. Will need to get rid of them since they do not mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleBasics_df.startYear.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleBasics_df.endYear.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleBasics_df.runtimeMinutes.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleBasics_df.genres.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After checking how many cells contain \"\\N\", decided to drop columns which have too many cells containing \"\\N\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping irrelevant columns \n",
    "titleBasics_df = titleBasics_df.drop(['endYear','runtimeMinutes'],axis=1)\n",
    "titleBasics_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading title.ratings.tsv file into a DataFrame for inspection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading title.ratings.tsv file from s3 bucket and loading data into DataFrame\n",
    "titleRatings_df = pd.read_csv(\"s3://mlmovieinfofiles/title.ratings.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titleRatings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data types\n",
    "titleRatings_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming confusing column names\n",
    "titleRatings_df = titleRatings_df.rename(columns={'tconst': 'titleId'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate rows in titleRatings_df \n",
    "duplicate_Ratingsrows_df = titleRatings_df[titleRatings_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_Ratingsrows_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking the dimensionality of the DataFrame\n",
    "titleRatings_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Outliers in titleRatings_df Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying a boxplot for titleRatings_df\n",
    "ratingsdata = (titleRatings_df.averageRating,titleRatings_df.numVotes)\n",
    "\n",
    "red_square = dict(markerfacecolor='r', marker='s')\n",
    "fig, ax = plt.subplots()\n",
    "ax.set_title('Title Ratings Boxplot')\n",
    "ax.set_xlabel('Ratings')\n",
    "\n",
    "ax.boxplot(ratingsdata, vert=False, flierprops=red_square)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying a scatterplot for titleRatings_df\n",
    "x = titleRatings_df.averageRating\n",
    "y = titleRatings_df.numVotes\n",
    "\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the IQR score technique to detect and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q1 = titleRatings_df.quantile(0.25)\n",
    "Q3 = titleRatings_df.quantile(0.75)\n",
    "IQR = (Q3 - Q1)\n",
    "print(IQR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing outliers\n",
    "titleRatings_df = titleRatings_df[~((titleRatings_df < (Q1 - 1.5 * IQR)) |(titleRatings_df > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
    "titleRatings_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Displaying a scatterplot after outliers have been removed\n",
    "x = titleRatings_df.averageRating\n",
    "y = titleRatings_df.numVotes\n",
    "\n",
    "\n",
    "plt.scatter(x, y, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Joining titleAkas_df, titleBasics_df and titleRatings_df Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "#first joining titleBasics_df to titleRatings_df\n",
    "ratingsBasics_df = pd.merge(titleRatings_df, titleBasics_df,on='titleId')\n",
    "\n",
    "ratingsBasics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dimensionality of joined DataFrame\n",
    "ratingsBasics_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Assigning rows in titleAkas_df DataFrame with isOriginalTitle value \"1\" to a new dataframe\n",
    "titleAkasOriginals_df = titleAkas_df[titleAkas_df.isOriginalTitle=='1']\n",
    "titleAkasOriginals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining titleAkasOriginals_df to ratingsBasics_df\n",
    "ratingsBasicsAkas_df = pd.merge(ratingsBasics_df, titleAkasOriginals_df,on='titleId')\n",
    "ratingsBasicsAkas_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data types of joind DataFrame\n",
    "ratingsBasicsAkas_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if any row in joined DataFrame has null value\n",
    "ratingsBasicsAkas_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dimensionality of joined DataFrame\n",
    "ratingsBasicsAkas_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate rows in ratingsBasicsAkas_df\n",
    "duplicate_joinedData_df = ratingsBasicsAkas_df[ratingsBasicsAkas_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicate_joinedData_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some feature engineering on columns in DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature engineering for titleType column\n",
    "ratingsBasicsAkas_df['titleType'] = np.where(ratingsBasicsAkas_df['titleType']=='tvShort', 'short', ratingsBasicsAkas_df['titleType'])\n",
    "\n",
    "ratingsBasicsAkas_df['titleType'] = np.where(ratingsBasicsAkas_df['titleType']=='tvMovie', 'movie', ratingsBasicsAkas_df['titleType'])\n",
    "\n",
    "ratingsBasicsAkas_df['titleType'] = np.where(ratingsBasicsAkas_df['titleType']=='tvMiniSeries', 'tvSeries', ratingsBasicsAkas_df['titleType'])\n",
    "\n",
    "ratingsBasicsAkas_df['titleType'] = np.where(ratingsBasicsAkas_df['titleType']=='videoGame', 'video', ratingsBasicsAkas_df['titleType'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar chart for data in column titleType\n",
    "sns.countplot(x='titleType', data=ratingsBasicsAkas_df)\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noticed some of the cells in the DataFrame still contain \"\\N\". Checking to see how many cells containing this data are in each column. Will need to get rid of them since they do not mean anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.startYear.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.genres.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.region.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping irrelevant columns \n",
    "ratingsBasicsAkas_df = ratingsBasicsAkas_df.drop(['ordering','title','region','isOriginalTitle'],axis=1)\n",
    "ratingsBasicsAkas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of a few rows that still contain \"\\N\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.genres.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df = ratingsBasicsAkas_df[ratingsBasicsAkas_df.genres != '\\\\N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring rows in genres containing \"\\N\" have been removed\n",
    "ratingsBasicsAkas_df.genres.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.startYear.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df = ratingsBasicsAkas_df[ratingsBasicsAkas_df.startYear != '\\\\N']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsBasicsAkas_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensuring rows in startYear containing \"\\N\" have been removed\n",
    "ratingsBasicsAkas_df.startYear.str.count(\"\\\\\\\\N\").sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping some columns to do more feature engineering on column titletype\n",
    "convertData = ratingsBasicsAkas_df.drop(['titleId','averageRating','numVotes','originalTitle','isAdult','startYear','genres'],axis=1)\n",
    "\n",
    "convertData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical data found in column titleType into numerical data\n",
    "cat_vars = ['titleType' ]\n",
    "for var in cat_vars:\n",
    "    catList = 'var'+'_'+var\n",
    "    catList = pd.get_dummies(convertData[var], prefix=var)\n",
    "    data1 = convertData.join(catList)\n",
    "   \n",
    "    \n",
    "data_vars = data1.columns.values.tolist()\n",
    "to_keep = [i for i in data_vars if i not in cat_vars]\n",
    "data_final=data1[to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Joining ratingsBasicsAkas_df to data_final after completing feature engineering on column titleType\n",
    "trainData_df = pd.merge(ratingsBasicsAkas_df, data_final,on='primaryTitle')\n",
    "trainData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping columns that can not be used as features for the K-means model\n",
    "trainData_df = trainData_df.drop(['titleId','titleType','originalTitle'],axis=1)\n",
    "trainData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#changing index of trainData_df to primaryTitle + genres\n",
    "trainData_df.index=trainData_df['primaryTitle'] + \"-\" + trainData_df['genres'].astype(object)\n",
    "drop=[\"primaryTitle\" , \"genres\"]\n",
    "trainData_df.drop(drop, axis=1, inplace=True)\n",
    "trainData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging columns in trainData_df DataFrame\n",
    "trainData_df = trainData_df[['startYear', 'numVotes', 'averageRating', 'isAdult','titleType_movie','titleType_short','titleType_tvEpisode','titleType_tvSeries','titleType_tvSpecial','titleType_video']]\n",
    "trainData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking data types \n",
    "trainData_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking dimensionality of DataFrame\n",
    "trainData_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate rows in trainData_df\n",
    "trainDataduplicates_df = trainData_df[trainData_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", trainDataduplicates_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates in trainData_df\n",
    "trainData_df = trainData_df.drop_duplicates()\n",
    "trainData_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all data types to float\n",
    "train_data = trainData_df.values.astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the K-Means model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.session import Session\n",
    "from sagemaker import KMeans\n",
    "import boto3\n",
    "import os\n",
    "import mxnet as mx\n",
    "from random import randint\n",
    "\n",
    "role = get_execution_role()\n",
    "bucket_name = 'mlmovieinfofiles'\n",
    "data_location = 's3://{}/data'.format(bucket_name)\n",
    "output_location = 's3://{}/output'.format(bucket_name)\n",
    "\n",
    "print('training data will be uploaded to: {}'.format(data_location))\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))\n",
    "\n",
    "#defining the hyperparameters of Kmeans model and specifying 10 clusters to be identified\n",
    "num_clusters = 10\n",
    "kmeans = KMeans(role=role,\n",
    "                instance_count=1,\n",
    "                instance_type='ml.m5.xlarge',\n",
    "                output_path=output_location,              \n",
    "                k=num_clusters,\n",
    "                data_path=data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kmeans.fit(kmeans.record_set(train_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up hosting for the model\n",
    "\n",
    "Deploying the model we just trained behind a real-time hosted endpoint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "kmeans_predictor = kmeans.deploy(initial_instance_count=1,\n",
    "                                 instance_type='ml.m4.xlarge')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Passing in the original training set to get the labels for each entry. Had to pass the original training set in chunks since there is a limit on how much of the training set you can pass. This will give us which cluster each movie/movie watcher belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result=kmeans_predictor.predict(train_data)\n",
    "result=kmeans_predictor.predict(train_data[0:98300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=kmeans_predictor.predict(train_data[98300:150000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=kmeans_predictor.predict(train_data[150000:179793])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breakdown of cluster counts and the distribution of clusters in each chunck of the training set passed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = [r.label['closest_cluster'].float32_tensor.values[0] for r in result]\n",
    "pd.DataFrame(cluster_labels)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels1 = [r.label['closest_cluster'].float32_tensor.values[0] for r in result1]\n",
    "pd.DataFrame(cluster_labels1)[0].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels2 = [r.label['closest_cluster'].float32_tensor.values[0] for r in result2]\n",
    "pd.DataFrame(cluster_labels2)[0].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mapping cluster labels back to each movie. This has to be done in chunks since distribution of clusters was done in chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = trainData_df.iloc[0:98300]\n",
    "traindata1 = trainData_df.iloc[98300:150000]\n",
    "traindata2 = trainData_df.iloc[150000:179793]\n",
    "traindata['clusterLabels']=list(map(int, cluster_labels))\n",
    "traindata1['clusterLabels']=list(map(int, cluster_labels1))\n",
    "traindata2['clusterLabels']=list(map(int, cluster_labels2))\n",
    "finalData = pd.concat([traindata,traindata1,traindata2])\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#resetting index and renaming index column(made up of primaryTitle + titleType) as Title \n",
    "finalData.reset_index(level=0, inplace=True)\n",
    "finalData = finalData.rename(columns={'index': 'Title'})\n",
    "finalData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting data in column Title(splitting primaryTitle and titleType) \n",
    "split_df = finalData[\"Title\"].str.split(\"-\", n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining newly created columns due to Title split to finalData Dataframe\n",
    "finalData_df = pd.merge(finalData, split_df,right_index=True,left_index=True)\n",
    "finalData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping numerical data columns for previously created titleType features\n",
    "finalData_df = finalData_df.drop(['Title','titleType_movie','titleType_short','titleType_tvEpisode','titleType_tvSeries','titleType_tvSpecial','titleType_video'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#renaming newly added columns created out of Title split\n",
    "finalData_df = finalData_df.rename(columns={0: 'Title'})\n",
    "finalData_df = finalData_df.rename(columns={1:'titleType'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rearranging columns in the DataFrame\n",
    "finalData_df = finalData_df[['Title', 'titleType','startYear','numVotes', 'averageRating','isAdult','clusterLabels' ]]\n",
    "finalData_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking for duplicate rows in finalData_df \n",
    "duplicatesData_df = finalData_df[finalData_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", duplicatesData_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping duplicates in finalData_df\n",
    "finalData_df = finalData_df.drop_duplicates()\n",
    "finalData_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkconcludeduplicates_df = finalData_df[finalData_df.duplicated()]\n",
    "print(\"number of duplicate rows: \", checkconcludeduplicates_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting column Title data type to string\n",
    "finalData_df['Title'] = finalData_df['Title'].astype('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1=finalData_df[finalData_df['clusterLabels']==0]\n",
    "cluster2=finalData_df[finalData_df['clusterLabels']==1]\n",
    "cluster3=finalData_df[finalData_df['clusterLabels']==2]\n",
    "cluster4=finalData_df[finalData_df['clusterLabels']==3]\n",
    "cluster5=finalData_df[finalData_df['clusterLabels']==4]\n",
    "cluster6=finalData_df[finalData_df['clusterLabels']==5]\n",
    "cluster7=finalData_df[finalData_df['clusterLabels']==6]\n",
    "cluster8=finalData_df[finalData_df['clusterLabels']==7]\n",
    "cluster9=finalData_df[finalData_df['clusterLabels']==8]\n",
    "cluster10=finalData_df[finalData_df['clusterLabels']==9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(kmeans_predictor.endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deleting endpoints\n",
    "sagemaker.Session().delete_endpoint(kmeans_predictor.endpoint_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Suggesting Movies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster1_movies = cluster1['Title'].to_list()\n",
    "movie_watcher1 = cluster1_movies[1]\n",
    "print(\"Movie Watcher 1 watched: \" + movie_watcher1)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster2_movies = cluster2['Title'].to_list()\n",
    "movie_watcher2 = cluster2_movies[1]\n",
    "print(\"Movie Watcher 2 watched: \" + movie_watcher2)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster3_movies = cluster3['Title'].to_list()\n",
    "movie_watcher3 = cluster3_movies[2]\n",
    "print(\"Movie Watcher 3 watched: \" + movie_watcher3)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster4_movies = cluster4['Title'].to_list()\n",
    "movie_watcher4 = cluster4_movies[3]\n",
    "print(\"Movie Watcher 4 watched: \" + movie_watcher4)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster5_movies = cluster5['Title'].to_list()\n",
    "movie_watcher5 = cluster1_movies[4]\n",
    "print(\"Movie Watcher 5 watched: \" + movie_watcher5)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster6_movies = cluster6['Title'].to_list()\n",
    "movie_watcher6 = cluster6_movies[5]\n",
    "print(\"Movie Watcher 6 watched: \" + movie_watcher6)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster7_movies = cluster7['Title'].to_list()\n",
    "movie_watcher7 = cluster7_movies[6]\n",
    "print(\"Movie Watcher 7 watched: \" + movie_watcher7)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster8_movies = cluster8['Title'].to_list()\n",
    "movie_watcher8 = cluster8_movies[7]\n",
    "print(\"Movie Watcher 8 watched: \" + movie_watcher8)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster9_movies = cluster9['Title'].to_list()\n",
    "movie_watcher9 = cluster9_movies[8]\n",
    "print(\"Movie Watcher 9 watched: \" + movie_watcher9)\n",
    "print(\"\\n\")\n",
    "\n",
    "cluster10_movies = cluster10['Title'].to_list()\n",
    "movie_watcher10 = cluster10_movies[9]\n",
    "print(\"Movie Watcher 10 watched: \" + movie_watcher10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher1).any():\n",
    "    watcheddf1 = finalData_df[finalData_df['Title'].str.contains(movie_watcher1)==True]\n",
    "    index1=watcheddf1.index.values.astype(int)[0]\n",
    "    labelvalue1 = finalData_df['clusterLabels'].values[index1]\n",
    "    newdf1 = finalData_df[finalData_df['clusterLabels']==labelvalue1]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher1 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies1 = newdf1['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen1 = len(list_of_movies1)\n",
    "    while i<11:   \n",
    "        value1 = randint(0, checklistlen1)\n",
    "        if movie_watcher1 == list_of_movies1[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies1[value1])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher2).any():\n",
    "    watcheddf2 = finalData_df[finalData_df['Title'].str.contains(movie_watcher2)==True]\n",
    "    index2=watcheddf2.index.values.astype(int)[0]\n",
    "    labelvalue2 = finalData_df['clusterLabels'].values[index2]\n",
    "    newdf2 = finalData_df[finalData_df['clusterLabels']==labelvalue2]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher2 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies2 = newdf2['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen2 = len(list_of_movies2)\n",
    "    while i<11:   \n",
    "        value2 = randint(0, checklistlen2)\n",
    "        if movie_watcher2 == list_of_movies2[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies2[value2])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher3).any():\n",
    "    watcheddf3 = finalData_df[finalData_df['Title'].str.contains(movie_watcher3)==True]\n",
    "    index3=watcheddf3.index.values.astype(int)[0]\n",
    "    labelvalue3 = finalData_df['clusterLabels'].values[index3]\n",
    "    newdf3 = finalData_df[finalData_df['clusterLabels']==labelvalue3]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher3 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies3 = newdf3['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen3 = len(list_of_movies3)\n",
    "    while i<11:   \n",
    "        value3 = randint(0, checklistlen3)\n",
    "        if movie_watcher3 == list_of_movies3[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies3[value3])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher4).any():\n",
    "    watcheddf4 = finalData_df[finalData_df['Title'].str.contains(movie_watcher4)==True]\n",
    "    index4=watcheddf4.index.values.astype(int)[0]\n",
    "    labelvalue4 = finalData_df['clusterLabels'].values[index4]\n",
    "    newdf4 = finalData_df[finalData_df['clusterLabels']==labelvalue4]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher4 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies4 = newdf4['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen4 = len(list_of_movies4)\n",
    "    while i<11:   \n",
    "        value4 = randint(0, checklistlen4)\n",
    "        if movie_watcher4 == list_of_movies4[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies4[value4])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher5).any():\n",
    "    watcheddf5 = finalData_df[finalData_df['Title'].str.contains(movie_watcher5)==True]\n",
    "    index5=watcheddf5.index.values.astype(int)[0]\n",
    "    labelvalue5 = finalData_df['clusterLabels'].values[index5]\n",
    "    newdf5 = finalData_df[finalData_df['clusterLabels']==labelvalue5]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher5 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies5 = newdf5['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen5 = len(list_of_movies5)\n",
    "    while i<11:   \n",
    "        value5 = randint(0, checklistlen5)\n",
    "        if movie_watcher5 == list_of_movies5[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies5[value5])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher6).any():\n",
    "    watcheddf6 = finalData_df[finalData_df['Title'].str.contains(movie_watcher6)==True]\n",
    "    index6=watcheddf6.index.values.astype(int)[0]\n",
    "    labelvalue6 = finalData_df['clusterLabels'].values[index6]\n",
    "    newdf6 = finalData_df[finalData_df['clusterLabels']==labelvalue6]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher6 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies6 = newdf6['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen6 = len(list_of_movies6)\n",
    "    while i<11:   \n",
    "        value6 = randint(0, checklistlen6)\n",
    "        if movie_watcher6 == list_of_movies6[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies6[value6])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher7).any():\n",
    "    watcheddf7 = finalData_df[finalData_df['Title'].str.contains(movie_watcher7)==True]\n",
    "    index7=watcheddf7.index.values.astype(int)[0]\n",
    "    labelvalue7 = finalData_df['clusterLabels'].values[index7]\n",
    "    newdf7 = finalData_df[finalData_df['clusterLabels']==labelvalue7]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher7 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies7 = newdf7['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen7 = len(list_of_movies7)\n",
    "    while i<11:   \n",
    "        value7 = randint(0, checklistlen7)\n",
    "        if movie_watcher7 == list_of_movies7[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies7[value7])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher8).any():\n",
    "    watcheddf8 = finalData_df[finalData_df['Title'].str.contains(movie_watcher8)==True]\n",
    "    index8=watcheddf8.index.values.astype(int)[0]\n",
    "    labelvalue8 = finalData_df['clusterLabels'].values[index8]\n",
    "    newdf8 = finalData_df[finalData_df['clusterLabels']==labelvalue8]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher8 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies8 = newdf8['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen8 = len(list_of_movies8)\n",
    "    while i<11:   \n",
    "        value8 = randint(0, checklistlen8)\n",
    "        if movie_watcher8 == list_of_movies8[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies8[value8])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher9).any():\n",
    "    watcheddf9 = finalData_df[finalData_df['Title'].str.contains(movie_watcher9)==True]\n",
    "    index9=watcheddf9.index.values.astype(int)[0]\n",
    "    labelvalue9 = finalData_df['clusterLabels'].values[index9]\n",
    "    newdf9 = finalData_df[finalData_df['clusterLabels']==labelvalue9]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher9 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies9 = newdf9['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen9 = len(list_of_movies9)\n",
    "    while i<11:   \n",
    "        value9 = randint(0, checklistlen9)\n",
    "        if movie_watcher9 == list_of_movies9[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies9[value9])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First checking if movie title exist in DataFrame. If yes, get cluster label and suggest movie titles that belong to the same cluster\n",
    "\n",
    "if finalData_df['Title'].str.match(movie_watcher10).any():\n",
    "    watcheddf10 = finalData_df[finalData_df['Title'].str.contains(movie_watcher10)==True]\n",
    "    index10=watcheddf10.index.values.astype(int)[0]\n",
    "    labelvalue10 = finalData_df['clusterLabels'].values[index10]\n",
    "    newdf10 = finalData_df[finalData_df['clusterLabels']==labelvalue10]\n",
    "\n",
    "    print(\"You finished watching: \" + movie_watcher10 + \".\")\n",
    "    print(\"Try one of these titles next.\")\n",
    "    print(\"\\n\")\n",
    "    \n",
    "    list_of_movies10 = newdf10['Title'].to_list()   \n",
    "    i = 0\n",
    "    checklistlen10 = len(list_of_movies10)\n",
    "    while i<11:   \n",
    "        value10 = randint(0, checklistlen10)\n",
    "        if movie_watcher10 == list_of_movies10[i]:       \n",
    "            i+=1\n",
    "        else:\n",
    "            print(list_of_movies10[value10])\n",
    "            i+=1\n",
    "else:\n",
    "    print('Sorry, we can not suggest other movies based on the movie title you just entered!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
